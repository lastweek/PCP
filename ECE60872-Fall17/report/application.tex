\section{Resilient Edge Computing}
\label{sec:resilient-egde}

This section presents our solutions to achieve resilient edge computing.
Due to the limitation of simulation, we believe only real implementation can
fully explore the potential benefits and challenges of edge computing.
As we've discussed in section~\ref{sec:computing-models}, we only target Type 3 computing model.

\subsection{Load Balancing}
\label{sec:load-balancing}
Balancing workload, or efficient job scheduling among multiple edge devices is key for edge computing
to achieve high performance while providing high availability and reliability.
Places with high attractiveness (e.g., cafeteria) will have hundreds of mobile devices,
or thousands of mobile applications running at the same time. Multiple edge devices
will be deployed in these highly attractive places. Load balancing among these
edge devices can maximize resource usage, maximize throughput and minimize response time.
Unlike datacenter-scale systems, which require complex scheduling algorithms~\cite{DRF-NSDI11,Borg-Eurosys15},
scheduling among edge devices should resemble the idea of real-time scheduling in distributed systems~\cite{rt-sched98}.

Normally, the jobs offloaded from mobile devices to edge devices have well-defined behaviour.
For example, machine learning applications upload the sample from mobile device, and the
service running on edge devices will perform prediction. Unlike training, the computation
of prediction process normally is short and fixed. Also for image-processing applications, the
service running on edge devices will perform certain computation on user-uploaded images, the
computation time for each image is normally known and predictable. Based on this finding,
we envision applications deployed in edge computing infrastructure will provide a high-precision runtime prediction.

For each edge device, it will perform First-In-First-Out (FIFO) policy. Since each job's runtime
is provided by application services, system software on edge devices is able to predict the total waiting time of each job
on the waiting queue efficiently. Every edge device needs to monitor if a job should be offloaded to another edge device,
if so, that job will be migrated to others.
In order to be able to make such a decision, all edge devices need to have some global knowledge
of others. This can be simply achieved by exchanging information among edge devices periodically.
Once such global knowledge is available, the decision can be made as follows: Assume there are \(N\)
edge devices in a system. Each edge device has a current estimated waiting time for a new job, \(EW\).
System software will update and exchange \(EW\) periodically.
The cost to migrate a job between edge devices is \(C\). Suppose at time \(t\), edge device \(E_i\) is
checking if job \(J\) should be migrated, it will find the \(min(EW_k + C)\).
If \(min(EW_k + C)\) is smaller than its own \(EW_i\), then edge device \(E_i\) will initiate the migration
to edge device \(E_k\). A simple but effective optimization is: if both peer edge device and cloud are
candidates for migration, the algorithm can favor edge device over cloud. Because normally edge device
has lower network latency for response.

\subsection{Policy for Failure Handling}
\label{sec:policy-fault}
As we've discussed in section~\ref{sec:failure-models}, resilient edge computing needs to
take care of edge device crash and network failures. As a common practice, we assume applications running on mobile
devices have their own mechanisms to detect failures, e.g., software timeout. The system
software running on edge devices also have a set of standard liveness detection mechanisms.

Once failure is detected, applications on mobile devices and system software on edge devices
should immediately take actions to mask this failure for end-users. We describe the policies below.

\hfill\break
\noindent \textbf{System Software on Edge Device.}
If the network to cloud is unreachable, edge device who has jobs offloaded to cloud previously should
immediately take the responsibility of executing the jobs. If peer edge device is unreachable,
edge device should immediately announce this information to all other edge devices and mobile devices
in its region. To provide high availability and reliability, system software running on edge devices
will also integrate all standard fault-tolerant mechanisms from distributed system years practice\cite{cavage-queue13,google-acm16}.

\hfill\break
\noindent \textbf{Application on Mobile Device.}
Once failure is detected by software timeout, applications on mobile
devices should immediately re-initialize the offloading process. It should send the request
to another live egde device if there is any other available edge devices in the system, otherwise
it should send the request directly to the cloud. Each application should have its own well-defined
running time prediction: a small estimated timeout may lead to false positives, while a large
guess may affect user experience.

\subsection{Mechanism for Failure Handling}
\label{sec:mechanism-fault}
Above we've discussed the general policies to achieve resilient edge computing, we will discuss
the general implementation for such policies in this section. Note that we only discuss the
implementation issues introduced by adding edge computing into current architecture:
mobile applications already have its design principles~\cite{mobi-comp-principle}, distributed systems
also have various methodical approach and lessons~\cite{cavage-queue13,google-acm16}. The mechanisms
presented in this section only address the policies we've discussed in section~\ref{sec:policy-fault}.

\hfill\break
\noindent \textbf{System Software on Edge Device.}
a) System software running on multiple edge devices needs to provide a runtime for different services.
It can be VM-based~\cite{cloudlets09}, it also can be application-specific. Application-specifc means
mobile application developers need to provide a runtime in edge servers. The application-specific runtime is
running on all edge devices, and all the runtime combined together provide the necessary functionalities
for resilient edge computing. VM-based solution provides a consistent view and eases mobile application programmer's burden,
but it limits the scope of application-awared scheduling. Instead, application-specifc runtime has the freedom
to choose the best management solution it see fit.
b) System software on edge devices need to advertise themselves and provide a general set of APIs (e.g., RESTful APIs).
To use edge servers, mobile applications first need to discover available edge devices nearby. After that, mobile applications
will be able to deploy and communicate with the services running on edge devices.

\hfill\break
\noindent \textbf{Application on Mobile Device.}
Mobile applications first need to find if there are any edge devices nearby. If found, they will try to communicate with
their own services running on edge devices. Assume the service is not deployed in the first run, mobile applications should
be able to use the general APIs exported by system software on edge device, to deploy the services on edge devices.
Once deployed, mobile application will offload its computation to edge devices. Mobile applications need to maintain a
set of software timers to monitor all outgoing jobs. Once a timer fired, mobile applications should immediately follow the
policies described in section~\ref{sec:policy-fault}. Implementation is OS-specific, but the rules apply.
